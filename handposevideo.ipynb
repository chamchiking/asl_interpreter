{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba5d3d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import copy\n",
    "import argparse\n",
    "import itertools\n",
    "import os\n",
    "from collections import Counter\n",
    "from collections import deque\n",
    "\n",
    "from utils.cvfpscalc import CvFpsCalc\n",
    "# from model import KeyPointClassifier\n",
    "# from model.point_history_classifier.point_history_classifier import PointHistoryClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d317070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# import numpy as np\n",
    "\n",
    "# class KeyPointClassifier(object):\n",
    "#     def __init__(\n",
    "#         self,\n",
    "#         model_path='./model/keypoint_classifier/keypoint_classifier.tflite',\n",
    "#         num_threads=1,\n",
    "#     ):\n",
    "#         self.interpreter = tf.lite.Interpreter(model_path=model_path,\n",
    "#                                                num_threads=num_threads)\n",
    "\n",
    "#         self.interpreter.allocate_tensors()\n",
    "#         self.input_details = self.interpreter.get_input_details()\n",
    "#         self.output_details = self.interpreter.get_output_details()\n",
    "\n",
    "#     def __call__(\n",
    "#         self,\n",
    "#         landmark_list,\n",
    "#     ):\n",
    "#         input_details_tensor_index = self.input_details[0]['index']\n",
    "#         self.interpreter.set_tensor(\n",
    "#             input_details_tensor_index,\n",
    "#             np.array([landmark_list], dtype=np.float32))\n",
    "#         self.interpreter.invoke()\n",
    "\n",
    "#         output_details_tensor_index = self.output_details[0]['index']\n",
    "\n",
    "#         result = self.interpreter.get_tensor(output_details_tensor_index)\n",
    "\n",
    "#         result_index = np.argmax(np.squeeze(result))\n",
    "\n",
    "#         return result_index\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6db28ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "objc[4950]: Class CaptureDelegate is implemented in both /Users/mincheol/miniforge3/envs/tensorflow/lib/python3.9/site-packages/cv2/cv2.abi3.so (0x10d8d2490) and /Users/mincheol/miniforge3/envs/tensorflow/lib/python3.9/site-packages/mediapipe/.dylibs/libopencv_videoio.3.4.16.dylib (0x283860860). One of the two will be used. Which one is undefined.\n",
      "objc[4950]: Class CVWindow is implemented in both /Users/mincheol/miniforge3/envs/tensorflow/lib/python3.9/site-packages/cv2/cv2.abi3.so (0x10d8d24e0) and /Users/mincheol/miniforge3/envs/tensorflow/lib/python3.9/site-packages/mediapipe/.dylibs/libopencv_highgui.3.4.16.dylib (0x282404a68). One of the two will be used. Which one is undefined.\n",
      "objc[4950]: Class CVView is implemented in both /Users/mincheol/miniforge3/envs/tensorflow/lib/python3.9/site-packages/cv2/cv2.abi3.so (0x10d8d2508) and /Users/mincheol/miniforge3/envs/tensorflow/lib/python3.9/site-packages/mediapipe/.dylibs/libopencv_highgui.3.4.16.dylib (0x282404a90). One of the two will be used. Which one is undefined.\n",
      "objc[4950]: Class CVSlider is implemented in both /Users/mincheol/miniforge3/envs/tensorflow/lib/python3.9/site-packages/cv2/cv2.abi3.so (0x10d8d2530) and /Users/mincheol/miniforge3/envs/tensorflow/lib/python3.9/site-packages/mediapipe/.dylibs/libopencv_highgui.3.4.16.dylib (0x282404ab8). One of the two will be used. Which one is undefined.\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_hands = mp.solutions.hands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "592962b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--device\", type=int, default=0)\n",
    "    parser.add_argument(\"--width\", help=\"cap width\", type=int, default=960)\n",
    "    parser.add_argument(\"--height\", help=\"cap height\", type=int, default=540)\n",
    "    \n",
    "    parser.add_argument(\"--use_static_image_mode\", action='store_true')\n",
    "    parser.add_argument(\"--min_detection_confidence\",\n",
    "                        help=\"min_detection_confidence\",\n",
    "                        type=float,\n",
    "                        default=0.7)\n",
    "    parser.add_argument(\"--min_tracking_confidence\",\n",
    "                        help='min_tracking_confidence',\n",
    "                        type=int,\n",
    "                        default=0)\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "    return args\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0981b60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_bounding_rect(image, landmarks):\n",
    "    image_width, image_height = image.shape[1], image.shape[0]\n",
    "\n",
    "    landmark_array = np.empty((0, 2), int)\n",
    "\n",
    "    for _, landmark in enumerate(landmarks.landmark):\n",
    "        landmark_x = min(int(landmark.x * image_width), image_width - 1)\n",
    "        landmark_y = min(int(landmark.y * image_height), image_height - 1)\n",
    "\n",
    "        landmark_point = [np.array((landmark_x, landmark_y))]\n",
    "\n",
    "        landmark_array = np.append(landmark_array, landmark_point, axis=0)\n",
    "\n",
    "    x, y, w, h = cv.boundingRect(landmark_array)\n",
    "\n",
    "    return [x, y, x + w, y + h]\n",
    "\n",
    "\n",
    "def calc_landmark_list(image, landmarks):\n",
    "    image_width, image_height = image.shape[1], image.shape[0]\n",
    "\n",
    "    landmark_point = []\n",
    "\n",
    "    # Keypoint\n",
    "    for _, landmark in enumerate(landmarks.landmark):\n",
    "        landmark_x = min(int(landmark.x * image_width), image_width - 1)\n",
    "        landmark_y = min(int(landmark.y * image_height), image_height - 1)\n",
    "        # landmark_z = landmark.z\n",
    "\n",
    "        landmark_point.append([landmark_x, landmark_y])\n",
    "\n",
    "    return landmark_point\n",
    "\n",
    "\n",
    "def pre_process_landmark(landmark_list):\n",
    "    temp_landmark_list = copy.deepcopy(landmark_list)\n",
    "\n",
    "    # Convert to relative coordinates\n",
    "    base_x, base_y = 0, 0\n",
    "    for index, landmark_point in enumerate(temp_landmark_list):\n",
    "        if index == 0:\n",
    "            base_x, base_y = landmark_point[0], landmark_point[1]\n",
    "\n",
    "        temp_landmark_list[index][0] = temp_landmark_list[index][0] - base_x\n",
    "        temp_landmark_list[index][1] = temp_landmark_list[index][1] - base_y\n",
    "\n",
    "    # Convert to a one-dimensional list\n",
    "    temp_landmark_list = list(\n",
    "        itertools.chain.from_iterable(temp_landmark_list))\n",
    "\n",
    "    # Normalization\n",
    "    max_value = max(list(map(abs, temp_landmark_list)))\n",
    "\n",
    "    def normalize_(n):\n",
    "        return n / max_value\n",
    "\n",
    "    temp_landmark_list = list(map(normalize_, temp_landmark_list))\n",
    "\n",
    "    return temp_landmark_list\n",
    "\n",
    "\n",
    "def pre_process_point_history(image, point_history):\n",
    "    image_width, image_height = image.shape[1], image.shape[0]\n",
    "\n",
    "    temp_point_history = copy.deepcopy(point_history)\n",
    "\n",
    "    # Convert to relative coordinates\n",
    "    base_x, base_y = 0, 0\n",
    "    for index, point in enumerate(temp_point_history):\n",
    "        if index == 0:\n",
    "            base_x, base_y = point[0], point[1]\n",
    "\n",
    "        temp_point_history[index][0] = (temp_point_history[index][0] -\n",
    "                                        base_x) / image_width\n",
    "        temp_point_history[index][1] = (temp_point_history[index][1] -\n",
    "                                        base_y) / image_height\n",
    "\n",
    "    # Convert to a one-dimensional list\n",
    "    temp_point_history = list(\n",
    "        itertools.chain.from_iterable(temp_point_history))\n",
    "\n",
    "    return temp_point_history\n",
    "\n",
    "\n",
    "def logging_csv(number, mode, landmark_list, point_history_list):\n",
    "    if mode == 0:\n",
    "        pass\n",
    "    if mode == 1 and (0 <= number <= 9):\n",
    "        csv_path = 'model/keypoint_classifier/keypoint.csv'\n",
    "        with open(csv_path, 'a', newline=\"\") as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([number, *landmark_list])\n",
    "    if mode == 2 and (0 <= number <= 9):\n",
    "        csv_path = 'model/point_history_classifier/point_history.csv'\n",
    "        with open(csv_path, 'a', newline=\"\") as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([number, *point_history_list])\n",
    "    return\n",
    "\n",
    "\n",
    "def draw_landmarks(image, landmark_point):\n",
    "    if len(landmark_point) > 0:\n",
    "        # Thumb\n",
    "        cv.line(image, tuple(landmark_point[2]), tuple(landmark_point[3]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[2]), tuple(landmark_point[3]),\n",
    "                (255, 255, 255), 2)\n",
    "        cv.line(image, tuple(landmark_point[3]), tuple(landmark_point[4]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[3]), tuple(landmark_point[4]),\n",
    "                (255, 255, 255), 2)\n",
    "\n",
    "        # Index finger\n",
    "        cv.line(image, tuple(landmark_point[5]), tuple(landmark_point[6]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[5]), tuple(landmark_point[6]),\n",
    "                (255, 255, 255), 2)\n",
    "        cv.line(image, tuple(landmark_point[6]), tuple(landmark_point[7]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[6]), tuple(landmark_point[7]),\n",
    "                (255, 255, 255), 2)\n",
    "        cv.line(image, tuple(landmark_point[7]), tuple(landmark_point[8]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[7]), tuple(landmark_point[8]),\n",
    "                (255, 255, 255), 2)\n",
    "\n",
    "        # Middle finger\n",
    "        cv.line(image, tuple(landmark_point[9]), tuple(landmark_point[10]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[9]), tuple(landmark_point[10]),\n",
    "                (255, 255, 255), 2)\n",
    "        cv.line(image, tuple(landmark_point[10]), tuple(landmark_point[11]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[10]), tuple(landmark_point[11]),\n",
    "                (255, 255, 255), 2)\n",
    "        cv.line(image, tuple(landmark_point[11]), tuple(landmark_point[12]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[11]), tuple(landmark_point[12]),\n",
    "                (255, 255, 255), 2)\n",
    "\n",
    "        # Ring finger\n",
    "        cv.line(image, tuple(landmark_point[13]), tuple(landmark_point[14]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[13]), tuple(landmark_point[14]),\n",
    "                (255, 255, 255), 2)\n",
    "        cv.line(image, tuple(landmark_point[14]), tuple(landmark_point[15]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[14]), tuple(landmark_point[15]),\n",
    "                (255, 255, 255), 2)\n",
    "        cv.line(image, tuple(landmark_point[15]), tuple(landmark_point[16]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[15]), tuple(landmark_point[16]),\n",
    "                (255, 255, 255), 2)\n",
    "\n",
    "        # Little finger\n",
    "        cv.line(image, tuple(landmark_point[17]), tuple(landmark_point[18]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[17]), tuple(landmark_point[18]),\n",
    "                (255, 255, 255), 2)\n",
    "        cv.line(image, tuple(landmark_point[18]), tuple(landmark_point[19]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[18]), tuple(landmark_point[19]),\n",
    "                (255, 255, 255), 2)\n",
    "        cv.line(image, tuple(landmark_point[19]), tuple(landmark_point[20]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[19]), tuple(landmark_point[20]),\n",
    "                (255, 255, 255), 2)\n",
    "\n",
    "        # Palm\n",
    "        cv.line(image, tuple(landmark_point[0]), tuple(landmark_point[1]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[0]), tuple(landmark_point[1]),\n",
    "                (255, 255, 255), 2)\n",
    "        cv.line(image, tuple(landmark_point[1]), tuple(landmark_point[2]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[1]), tuple(landmark_point[2]),\n",
    "                (255, 255, 255), 2)\n",
    "        cv.line(image, tuple(landmark_point[2]), tuple(landmark_point[5]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[2]), tuple(landmark_point[5]),\n",
    "                (255, 255, 255), 2)\n",
    "        cv.line(image, tuple(landmark_point[5]), tuple(landmark_point[9]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[5]), tuple(landmark_point[9]),\n",
    "                (255, 255, 255), 2)\n",
    "        cv.line(image, tuple(landmark_point[9]), tuple(landmark_point[13]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[9]), tuple(landmark_point[13]),\n",
    "                (255, 255, 255), 2)\n",
    "        cv.line(image, tuple(landmark_point[13]), tuple(landmark_point[17]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[13]), tuple(landmark_point[17]),\n",
    "                (255, 255, 255), 2)\n",
    "        cv.line(image, tuple(landmark_point[17]), tuple(landmark_point[0]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[17]), tuple(landmark_point[0]),\n",
    "                (255, 255, 255), 2)\n",
    "\n",
    "    # Key Points\n",
    "    for index, landmark in enumerate(landmark_point):\n",
    "        if index == 0:  # 手首1\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),\n",
    "                      -1)\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)\n",
    "        if index == 1:  # 手首2\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),\n",
    "                      -1)\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)\n",
    "        if index == 2:  # 親指：付け根\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),\n",
    "                      -1)\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)\n",
    "        if index == 3:  # 親指：第1関節\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),\n",
    "                      -1)\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)\n",
    "        if index == 4:  # 親指：指先\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 8, (255, 255, 255),\n",
    "                      -1)\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 8, (0, 0, 0), 1)\n",
    "        if index == 5:  # 人差指：付け根\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),\n",
    "                      -1)\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)\n",
    "        if index == 6:  # 人差指：第2関節\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),\n",
    "                      -1)\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)\n",
    "        if index == 7:  # 人差指：第1関節\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),\n",
    "                      -1)\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)\n",
    "        if index == 8:  # 人差指：指先\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 8, (255, 255, 255),\n",
    "                      -1)\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 8, (0, 0, 0), 1)\n",
    "        if index == 9:  # 中指：付け根\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),\n",
    "                      -1)\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)\n",
    "        if index == 10:  # 中指：第2関節\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),\n",
    "                      -1)\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)\n",
    "        if index == 11:  # 中指：第1関節\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),\n",
    "                      -1)\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)\n",
    "        if index == 12:  # 中指：指先\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 8, (255, 255, 255),\n",
    "                      -1)\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 8, (0, 0, 0), 1)\n",
    "        if index == 13:  # 薬指：付け根\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),\n",
    "                      -1)\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)\n",
    "        if index == 14:  # 薬指：第2関節\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),\n",
    "                      -1)\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)\n",
    "        if index == 15:  # 薬指：第1関節\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),\n",
    "                      -1)\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)\n",
    "        if index == 16:  # 薬指：指先\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 8, (255, 255, 255),\n",
    "                      -1)\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 8, (0, 0, 0), 1)\n",
    "        if index == 17:  # 小指：付け根\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),\n",
    "                      -1)\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)\n",
    "        if index == 18:  # 小指：第2関節\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),\n",
    "                      -1)\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)\n",
    "        if index == 19:  # 小指：第1関節\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),\n",
    "                      -1)\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)\n",
    "        if index == 20:  # 小指：指先\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 8, (255, 255, 255),\n",
    "                      -1)\n",
    "            cv.circle(image, (landmark[0], landmark[1]), 8, (0, 0, 0), 1)\n",
    "\n",
    "    return image\n",
    "\n",
    "\n",
    "def draw_bounding_rect(use_brect, image, brect):\n",
    "    if use_brect:\n",
    "        # Outer rectangle\n",
    "        cv.rectangle(image, (brect[0], brect[1]), (brect[2], brect[3]),\n",
    "                     (0, 0, 0), 1)\n",
    "\n",
    "    return image\n",
    "\n",
    "\n",
    "def draw_info_text(image, brect, handedness, hand_sign_text,\n",
    "                   finger_gesture_text):\n",
    "    cv.rectangle(image, (brect[0], brect[1]), (brect[2], brect[1] - 22),\n",
    "                 (0, 0, 0), -1)\n",
    "\n",
    "    info_text = handedness.classification[0].label[0:]\n",
    "    if hand_sign_text != \"\":\n",
    "        info_text = info_text + ':' + hand_sign_text\n",
    "    cv.putText(image, info_text, (brect[0] + 5, brect[1] - 4),\n",
    "               cv.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1, cv.LINE_AA)\n",
    "\n",
    "    if finger_gesture_text != \"\":\n",
    "        cv.putText(image, \"Finger Gesture:\" + finger_gesture_text, (10, 60),\n",
    "                   cv.FONT_HERSHEY_SIMPLEX, 1.0, (0, 0, 0), 4, cv.LINE_AA)\n",
    "        cv.putText(image, \"Finger Gesture:\" + finger_gesture_text, (10, 60),\n",
    "                   cv.FONT_HERSHEY_SIMPLEX, 1.0, (255, 255, 255), 2,\n",
    "                   cv.LINE_AA)\n",
    "\n",
    "    return image\n",
    "\n",
    "\n",
    "def draw_point_history(image, point_history):\n",
    "    for index, point in enumerate(point_history):\n",
    "        if point[0] != 0 and point[1] != 0:\n",
    "            cv.circle(image, (point[0], point[1]), 1 + int(index / 2),\n",
    "                      (152, 251, 152), 2)\n",
    "\n",
    "    return image\n",
    "\n",
    "\n",
    "def draw_info(image, fps, mode, number):\n",
    "    cv.putText(image, \"FPS:\" + str(fps), (10, 30), cv.FONT_HERSHEY_SIMPLEX,\n",
    "               1.0, (0, 0, 0), 4, cv.LINE_AA)\n",
    "    cv.putText(image, \"FPS:\" + str(fps), (10, 30), cv.FONT_HERSHEY_SIMPLEX,\n",
    "               1.0, (255, 255, 255), 2, cv.LINE_AA)\n",
    "\n",
    "    mode_string = ['Logging Key Point', 'Logging Point History']\n",
    "    if 1 <= mode <= 2:\n",
    "        cv.putText(image, \"MODE:\" + mode_string[mode - 1], (10, 90),\n",
    "                   cv.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1,\n",
    "                   cv.LINE_AA)\n",
    "        if 0 <= number <= 9:\n",
    "            cv.putText(image, \"NUM:\" + str(number), (10, 110),\n",
    "                       cv.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1,\n",
    "                       cv.LINE_AA)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef8886f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For webcam testing!!!!!\n",
    "cap = cv.VideoCapture(0)\n",
    "with mp_hands.Hands(\n",
    "    model_complexity=0,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5) as hands:\n",
    "  while cap.isOpened():\n",
    "    success, image = cap.read()\n",
    "    if not success:\n",
    "      print(\"Ignoring empty camera frame.\")\n",
    "      # If loading a video, use 'break' instead of 'continue'.\n",
    "      continue\n",
    "\n",
    "    # To improve performance, optionally mark the image as not writeable to\n",
    "    # pass by reference.\n",
    "    image.flags.writeable = False\n",
    "    image = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
    "    results = hands.process(image)\n",
    "\n",
    "    # Draw the hand annotations on the image.\n",
    "    image.flags.writeable = True\n",
    "    image = cv.cvtColor(image, cv.COLOR_RGB2BGR)\n",
    "    if results.multi_hand_landmarks:\n",
    "      for hand_landmarks in results.multi_hand_landmarks:\n",
    "        mp_drawing.draw_landmarks(\n",
    "            image,\n",
    "            hand_landmarks,\n",
    "            mp_hands.HAND_CONNECTIONS,\n",
    "            mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "            mp_drawing_styles.get_default_hand_connections_style())\n",
    "    # Flip the image horizontally for a selfie-view display.\n",
    "    cv.imshow('MediaPipe Hands', cv.flip(image, 1))\n",
    "    if cv.waitKey(5) & 0xFF == 27:\n",
    "      break\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "546fe252",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect(\n",
    "    cap_device,\n",
    "    cap_width,\n",
    "    cap_height,\n",
    "    use_static_image_mode,\n",
    "    min_detection_confidence,\n",
    "    min_tracking_confidence\n",
    "):\n",
    "    use_brect = True\n",
    "\n",
    "    # Camera preparation ###############################################################\n",
    "    cap = cv.VideoCapture(cap_device)\n",
    "    cap.set(cv.CAP_PROP_FRAME_WIDTH, cap_width)\n",
    "    cap.set(cv.CAP_PROP_FRAME_HEIGHT, cap_height)\n",
    "    \n",
    "    # Model load #############################################################\n",
    "    mp_hands = mp.solutions.hands\n",
    "    hands = mp_hands.Hands(\n",
    "        static_image_mode=use_static_image_mode,\n",
    "        max_num_hands=1,\n",
    "        min_detection_confidence=min_detection_confidence,\n",
    "        min_tracking_confidence=min_tracking_confidence,\n",
    "    )\n",
    "    \n",
    "    keypoint_classifier = KeyPointClassifier()\n",
    "\n",
    "    # Read labels ###########################################################\n",
    "    keypoint_classifier_labels = sorted([n for n in os.listdir('asl_images_in') if not n.startswith('.')])\n",
    "\n",
    "    # FPS Measurement ########################################################\n",
    "    cvFpsCalc = CvFpsCalc(buffer_len=10)\n",
    "    \n",
    "    # Coordinate history #################################################################\n",
    "    history_length = 16\n",
    "    point_history = deque(maxlen=history_length)\n",
    "    \n",
    "    # Finger gesture history ################################################\n",
    "    finger_gesture_history = deque(maxlen=history_length)\n",
    "    \n",
    "    mode=0\n",
    "    number=-1\n",
    "    \n",
    "    while True:\n",
    "        fps = cvFpsCalc.get()\n",
    "        # Camera capture #####################################################\n",
    "        ret, image = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        image = cv.flip(image, 1)  # Mirror display\n",
    "        debug_image = copy.deepcopy(image)\n",
    "\n",
    "        # Detection implementation #############################################################\n",
    "        image = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
    "        print('2')\n",
    "        image.flags.writeable = False\n",
    "        results = hands.process(image)\n",
    "        image.flags.writeable = True\n",
    "        print('3')\n",
    "        #  ####################################################################\n",
    "        if results.multi_hand_landmarks is not None:\n",
    "            for hand_landmarks, handedness in zip(results.multi_hand_landmarks,\n",
    "                                                  results.multi_handedness):\n",
    "                # Bounding box calculation\n",
    "                brect = calc_bounding_rect(debug_image, hand_landmarks)\n",
    "                # Landmark calculation\n",
    "                landmark_list = calc_landmark_list(debug_image, hand_landmarks)\n",
    "\n",
    "                # Conversion to relative coordinates / normalized coordinates\n",
    "                pre_processed_landmark_list = pre_process_landmark(\n",
    "                    landmark_list)\n",
    "                pre_processed_point_history_list = pre_process_point_history(\n",
    "                    debug_image, point_history)\n",
    "                # Write to the dataset file\n",
    "                logging_csv(number, mode, pre_processed_landmark_list,\n",
    "                            pre_processed_point_history_list)\n",
    "\n",
    "                # Hand sign classification\n",
    "                hand_sign_id = keypoint_classifier(pre_processed_landmark_list)\n",
    "                if hand_sign_id == 2:  # Point gesture\n",
    "                    point_history.append(landmark_list[8])\n",
    "                else:\n",
    "                    point_history.append([0, 0])\n",
    "\n",
    "                # Drawing part\n",
    "                debug_image = draw_bounding_rect(use_brect, debug_image, brect)\n",
    "                debug_image = draw_landmarks(debug_image, landmark_list)\n",
    "                debug_image = draw_info_text(\n",
    "                    debug_image,\n",
    "                    brect,\n",
    "                    handedness,\n",
    "                    keypoint_classifier_labels[hand_sign_id],\n",
    "                    point_history_classifier_labels[most_common_fg_id[0][0]],\n",
    "                )\n",
    "        else:\n",
    "            point_history.append([0, 0])\n",
    "\n",
    "        debug_image = draw_point_history(debug_image, point_history)\n",
    "        debug_image = draw_info(debug_image, fps, mode, number)\n",
    "\n",
    "        # Screen reflection #############################################################\n",
    "        cv.imshow('Hand Gesture Recognition', debug_image)\n",
    "\n",
    "    cap.release()\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293c7c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "detect(0, 960, 540, True, 0.7, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ed883b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59649a80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
